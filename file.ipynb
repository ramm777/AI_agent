{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\kubey\\AppData\\Local\\Temp\\ipykernel_11268\\4133970029.py:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nInstall miniconda from the internet \\n    Add conda to PATH - \\n    Start Menu and search for \"Environment Variables.\"\\n    Click on \"Edit the system environment variables.\"\\n    In the System Properties window, click on \"Environment Variables.\"\\n    In the Environment Variables window, find and select the Path\\n    Add new C:\\\\ProgramData\\\\miniconda3\\\\Scripts (or where is yours)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  Working with Conda\n",
    "\n",
    "\"\"\"\n",
    "Install miniconda from the internet \n",
    "    Add conda to PATH - \n",
    "    Start Menu and search for \"Environment Variables.\"\n",
    "    Click on \"Edit the system environment variables.\"\n",
    "    In the System Properties window, click on \"Environment Variables.\"\n",
    "    In the Environment Variables window, find and select the Path\n",
    "    Add new C:\\ProgramData\\miniconda3\\Scripts (or where is yours)\n",
    "\"\"\"\n",
    "\n",
    "# $ conda create -n langchain python=3.12 -y # langchain is the name of virt env\n",
    "# $ conda env list # check all envs by below. * - mean active. I think base must be active\n",
    "\n",
    "# In power shell (admin): \n",
    "# Set-ExecutionPolicy RemoteSigned -Scope CurrentUser\n",
    "\n",
    "# $ conda activate langchain\n",
    "\n",
    "# $ pip install langchain langchain_openai langchain_community langgraph ipykernel python-dotenv\n",
    "\n",
    "# If pip's dependancy resolver Error: \n",
    "# $ pip install google-auth # must be <3.0.dev0,>=2.14.1\n",
    "\n",
    "# $ ipython kernel install --user --name=langchain\n",
    "\n",
    "# !pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a matter of opinion and can vary depending on personal preference\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52,\n",
       " ['sleep',\n",
       "  'wolfram-alpha',\n",
       "  'google-search',\n",
       "  'google-search-results-json',\n",
       "  'searx-search-results-json',\n",
       "  'bing-search',\n",
       "  'metaphor-search',\n",
       "  'ddg-search',\n",
       "  'google-books',\n",
       "  'google-lens',\n",
       "  'google-serper',\n",
       "  'google-scholar',\n",
       "  'google-finance',\n",
       "  'google-trends',\n",
       "  'google-jobs',\n",
       "  'google-serper-results-json',\n",
       "  'searchapi',\n",
       "  'searchapi-results-json',\n",
       "  'serpapi',\n",
       "  'dalle-image-generator',\n",
       "  'twilio',\n",
       "  'searx-search',\n",
       "  'merriam-webster',\n",
       "  'wikipedia',\n",
       "  'arxiv',\n",
       "  'golden-query',\n",
       "  'pubmed',\n",
       "  'human',\n",
       "  'awslambda',\n",
       "  'stackexchange',\n",
       "  'sceneXplain',\n",
       "  'graphql',\n",
       "  'openweathermap-api',\n",
       "  'dataforseo-api-search',\n",
       "  'dataforseo-api-search-json',\n",
       "  'eleven_labs_text2speech',\n",
       "  'google_cloud_texttospeech',\n",
       "  'read_file',\n",
       "  'reddit_search',\n",
       "  'news-api',\n",
       "  'tmdb-api',\n",
       "  'podcast-api',\n",
       "  'memorize',\n",
       "  'llm-math',\n",
       "  'open-meteo-api',\n",
       "  'requests',\n",
       "  'requests_get',\n",
       "  'requests_post',\n",
       "  'requests_patch',\n",
       "  'requests_put',\n",
       "  'requests_delete',\n",
       "  'terminal'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tools are classes that an Agent uses to interact with the world. https://python.langchain.com/api_reference/community/tools.html \n",
    "# load_tools() is only a shorthand function\n",
    "\n",
    "from langchain_community.agent_toolkits.load_tools import get_all_tool_names\n",
    "\n",
    "all_tool_names = get_all_tool_names()\n",
    "len(all_tool_names), all_tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks good\n",
    "# https://python.langchain.com/v0.1/docs/integrations/tools/golden_query/\n",
    "# google-jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_______________________________________________\\nJob Title: Machine Learning Resident - Client: Jotson (12 months)\\nCompany Name: Alberta Machine Intelligence Institute\\nLocation: Edmonton, AB, Canada\\nDescription: Salary:\\n\\nJoin us for a unique ML Resident role tackling time-series problems in the energy domain with ML/DL. Youll collaborate with a dynamic and fast-paced team of machine learning scientists and domain experts, developing innovative models and products with energy data.\\n\\n- Maithrreye Srinivasan, Machine Learning Scientist and Dave Staszak, Lead Machine Learning Scientist\\n\\nAbout the Role\\n\\nThis is a paid residency that will be undertaken over a twelve-month period with the potential to be hired by our client afterwards (note: at the discretion of the client and with the requirement of being located in Calgary at that time). The resident will be reporting to an Amii Machine Learning Scientist and regularly consult with the Client team to share insights and engage in knowledge transfer activities.\\n\\nAbout our Client\\n\\nJotson's mission is to help Canadians become informed and confident in making energy-related decisions. They achieve this by making household energy data easy to access, track, and understand. The company has decades of experience working in the energy industry and looks to apply its knowledge to bridge the gap between the energy sector and the everyday consumer.\\n\\nAbout the Project\\n\\nJotson aims to develop a machine-learning solution for detecting anomalies in energy consumption patterns for household and business properties. This solution will alert consumers when energy consumption or charges deviate from expected patterns. Anomaly detection plays a crucial role in monitoring and managing energy usage by flagging unusual consumption patterns or outliers. Anomalies may indicate:\\n• Equipment inefficiencies or failures.\\n• Opportunities to detect energy inefficiencies early and take corrective action.\\n• Misaligned energy systems or operational issues.\\n• Opportunities for energy savings or optimization.\\n• Inaccurate metering/billing that can lead to financial losses.\\n\\nRequired Skills / Expertise\\n\\nWere looking for a talented and enthusiastic individual with solid knowledge of machine learning and experience working with time series data.\\n\\nKey Responsibilities:\\n• Clean, preprocess, and curate historical energy usage datasets.\\n• Conduct exploratory data analysis to identify patterns and anomalies.\\n• Design, build, train, and evaluate ML/DL models\\n• Develop data and ML workflows\\n• Undertake applied research on ML techniques to address the limitations in existing models and develop new approaches\\n• Collaborate with project team and stakeholders to develop minimum viable products (MVPs) and client-centric solutions\\n\\nRequired Qualifications:\\n• Completion of a Computing Science or ML graduate program, MSc. or Ph.D\\n• Research or project experience working with time series data and classical time series models (ARIMA, Facebook Prophet, etc.)\\n• Solid understanding and experience in applications of deep learning techniques such as sequence models (RNNs, LSTMs, GRUs, Transformers, etc.) or multi task learning\\n• Proficient in Python programming language and related ML frameworks, libraries and toolkits (e.g. Scikit learn, Keras, Tensorflow, Pandas, Jupyter notebooks)\\n• A positive attitude towards learning and understanding a new applied domain\\n• Must be legally eligible to work in Canada\\n\\nPreferred Qualifications:\\n• Publication record in peer-reviewed academic conferences or relevant journals in machine learning\\n• Familiarity with time series anomaly detection methods\\n• Experience/familiarity with software engineering best practices\\n• Experience using cloud platforms (GCP, AWS, Azure, etc.)\\n\\nNon-Technical Requirements:\\n• Desire to take ownership of a problem and demonstrated leadership skills\\n• Interdisciplinary team player enthusiastic about working together to achieve excellence\\n• Capable of critical and independent thought\\n• Able to communicate technical concepts clearly and advise on the application of machine intelligence\\n• Intellectual curiosity and the desire to learn new things, techniques, and technologies\\n\\nWhy You Should Apply\\n\\nBesides gaining industry experience, additional perks include:\\n• Work under the mentorship of an Amii Lead Scientist for the duration of the project\\n• Participate in professional development activities\\n• Gain access to the Amii community and events\\n• Build your professional network\\n• The opportunity for a permanent machine learning role at the clients organization at the end of the term (at the clients discretion)\\n\\nLocation\\n\\nPreference for Calgary or Edmonton\\n\\nAbout Amii\\n\\nOne of Canadas three main institutes for artificial intelligence (AI) and machine learning, our world-renowned researchers drive fundamental and applied research at the University of Alberta (and other academic institutions), training some of the worlds top scientific talent. Our cross-functional teams work collaboratively with Alberta-based businesses and organizations to build AI capacity and translate scientific advancement into industry adoption and economic impact.\\n\\nHow to Apply\\n\\nIf this sounds like the opportunity you've been waiting for, please dont wait for the closing February 24, 2025 to apply - were excited to add a new member to the Amii team for this role, and the posting may come down sooner than the closing date if we find the right candidate before the posting closes! When sending your application, please send your resume and cover letter indicating why you think you'd be a fit for Amii. In your cover letter, please include one professional accomplishment you are most proud of and why.\\n\\nApplicants must be legally eligible to work in Canada at the time of application.\\n\\nAmii is an equal opportunity employer and values a diverse workforce. We encourage applications from all qualified individuals without regard to ethnicity, religion, gender identity, sexual orientation, age or disability. Accommodations for disability-related needs throughout the recruitment and selection process are available upon request. Any information provided by you for accommodations will be kept confidential and wont be used in the selection process.\\n_______________________________________________\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tool\n",
    "\n",
    "from langchain_community.tools.google_jobs import GoogleJobsQueryRun\n",
    "from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper\n",
    "\n",
    "api_key_serpapi = os.getenv('SERPAPI_API_KEY')\n",
    "os.environ[\"SERPAPI_API_KEY\"] = api_key_serpapi\n",
    "\n",
    "tool_googlejobs = GoogleJobsQueryRun(api_wrapper=GoogleJobsAPIWrapper())\n",
    "\n",
    "# Example usage or run(): \n",
    "tool_googlejobs.run(\"Can I get a list of 3 job posting related to machine learning in alberta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of LLMs:\n",
    "- Language models - input stings and generate strings. They are typically older and work best to answer individual user queries.\n",
    "- Chat model - inputs a sequence of messages, and generates responses that are contextually aware of the conversation flow. By default does not remember past conversations (stateless), but sometimes conversational memory is implemented. \n",
    "- Instruct models - optimized to follow specific instructions and perform tasks rather than engage in open-ended dialogue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of October 2023, several hot topics in AI continue to garner significant attention:\\n\\n1. **Generative AI**: The advancements in generative models, including large language models (LLMs) like GPT-4 and others, are a major focus. This includes their applications in content creation, code generation, art generation, and more.\\n\\n2. **Ethics and Bias in AI**: The discussion around the ethical implications of AI, including bias, transparency, and accountability, is increasingly urgent. Researchers and organizations are seeking ways to ensure AI systems are fair and responsible.\\n\\n3. **AI Safety and Alignment**: Ensuring that AI systems act in ways aligned with human values and intentions is a critical area of research, particularly as AI capabilities strengthen.\\n\\n4. **AI in Healthcare**: The use of AI for diagnostics, drug discovery, and personalized medicine is rapidly evolving and has profound implications for the healthcare industry.\\n\\n5. **Autonomous Systems**: The development and regulation of autonomous vehicles and drones are hot topics, particularly concerning safety and infrastructure.\\n\\n6. **AI and Climate Change**: Leveraging AI for environmental monitoring, sustainable practices, and climate modeling is gaining momentum in response to global climate challenges.\\n\\n7. **Quantum Computing and AI**: The intersection of quantum computing and AI is being explored, with potential implications for computational power and algorithm efficiency.\\n\\n8. **AI and Creativity**: The role of AI in creative fields—such as music, art, and literature—is a burgeoning topic, raising questions about creativity, authorship, and the nature of art.\\n\\nThese themes reflect ongoing research, public interest, and the societal implications of AI technologies, making them particularly relevant and \"hot\" in discussions about the future of AI.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 352, 'prompt_tokens': 28, 'total_tokens': 380, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-111ef297-b491-43c9-9d67-5e5c73933bac-0', usage_metadata={'input_tokens': 28, 'output_tokens': 352, 'total_tokens': 380, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat model\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "chat_model = ChatOpenAI(api_key=api_key, model='gpt-4o-mini')\n",
    "\n",
    "\n",
    "messages = [SystemMessage(content='You are a Scientist in AI.'),             # instruct a system to behave in certain way: tone, rules, how respond\n",
    "            HumanMessage(content=\"Which is the most hot topic in AI now?\")]  # input or queries made by the user/human    \n",
    "\n",
    "# Test chat model \n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This agent from LangChain is not good - langchain.agents.react.agent.create_react_agent\n",
    "- Better use from the LangGraph (offers a more flexible and full-featured)\n",
    "\n",
    "There are agent types in LangChain:\n",
    "\n",
    "- React agents: Use reasoning and actions to decide on the best steps \n",
    "- Multi-agent: Divide complicated problems into units of work that can be targeted by specialized agents \n",
    "- Conversational agents: Engage in dialogue and maintain context across multiple interactions \n",
    "- Structured chat agents: Parse inputs and outputs into structured formats \n",
    "- Tool calling agents: Use tools in a straightforward way \n",
    "- Self-ask with search: Split queries into smaller steps to handle them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_prompt = SystemMessage(\"You are a helpful bot named Chandler.\")\n",
    "agent = create_react_agent(chat_model, tools, state_modifier=system_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
