{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libraries:\n",
    "\n",
    "1) Install miniconda from the website\n",
    "2) Add conda to PATH:\n",
    "     - Start Menu and search for \"Environment Variables.\"\n",
    "     - Click on \"Edit the system environment variables.\"\n",
    "     - In the System Properties window, click on \"Environment Variables.\"\n",
    "     - In the Environment Variables window, find and select the Path.\n",
    "     - Add new: C:\\ProgramData\\miniconda3\\Scripts (or where yours is located).\n",
    "\n",
    "3) Install libs:\n",
    "\n",
    "Create a new virtual environment named 'langchain' with Python 3.12\n",
    "```\n",
    "conda create -n langchain python=3.12 -y\n",
    "```\n",
    "List all environments (the active one will be marked with an asterisk)\n",
    "```\n",
    "conda env list\n",
    "```\n",
    "In PowerShell (admin): Set the execution policy to RemoteSigned for the current user\n",
    "```\n",
    "Set-ExecutionPolicy RemoteSigned -Scope CurrentUser\n",
    "```\n",
    "\n",
    "```\n",
    "conda activate langchain\n",
    "pip install langchain langchain_openai langchain_community langgraph ipykernel python-dotenv\n",
    "```\n",
    "\n",
    "If you encounter a dependency resolver error with pip:\n",
    "```\n",
    "pip install google-auth # Must be <3.0.dev0,>=2.14.1\n",
    "```\n",
    "\n",
    "```\n",
    "ipython kernel install --user --name=langchain\n",
    "pip install google-search-results\n",
    "pip install matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.agent_toolkits.load_tools import get_all_tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  52\n",
      "sleep wolfram-alpha google-search google-search-results-json searx-search-results-json bing-search metaphor-search ddg-search google-books google-lens\n",
      "google-serper google-scholar google-finance google-trends google-jobs google-serper-results-json searchapi searchapi-results-json serpapi dalle-image-generator\n",
      "twilio searx-search merriam-webster wikipedia arxiv golden-query pubmed human awslambda stackexchange\n",
      "sceneXplain graphql openweathermap-api dataforseo-api-search dataforseo-api-search-json eleven_labs_text2speech google_cloud_texttospeech read_file reddit_search news-api\n",
      "tmdb-api podcast-api memorize llm-math open-meteo-api requests requests_get requests_post requests_patch requests_put\n",
      "requests_delete terminal\n"
     ]
    }
   ],
   "source": [
    "# load_tools() is only a shorthand function. It's better to properly use langchain_community.tools\n",
    "all_tool_names = get_all_tool_names()\n",
    "print('length: ', len(all_tool_names))\n",
    "\n",
    "for i in range(0, len(all_tool_names), 10):\n",
    "    print(\" \".join(all_tool_names[i:i+10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of LLMs:\n",
    "- Language models - input stings and generate strings. They are typically older and work best to answer individual user queries.\n",
    "- Chat model - inputs a sequence of messages, and generates responses that are contextually aware of the conversation flow. By default does not remember past conversations (stateless), but sometimes conversational memory is implemented. \n",
    "- Instruct models - optimized to follow specific instructions and perform tasks rather than engage in open-ended dialogue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As of my last update in October 2023, some of the hottest topics in AI included:\\n\\n1. **Generative AI**: This encompasses advancements in models like GPT (including fine-tuning for specific applications), image generation models (like DALL-E), and multi-modal AI systems that can integrate text, image, and audio processing.\\n\\n2. **AI Ethics and Regulation**: With the rapid deployment of AI technologies, there is an increasing focus on ethical considerations, biases in AI systems, and the need for regulatory frameworks to ensure responsible use.\\n\\n3. **Explainable AI (XAI)**: As AI systems become more complex, understanding and explaining their decisions to users has gained prominence. Researchers aim to develop methods that make AI's decision-making processes more transparent.\\n\\n4. **AI Safety and Robustness**: Ensuring that AI systems are secure, reliable, and resistant to adversarial attacks is critical, particularly as they are deployed in more sensitive areas like healthcare and autonomous vehicles.\\n\\n5. **AI in Climate Science**: Leveraging AI to tackle climate change, optimize energy use, and develop sustainable technologies is seeing increased research interest.\\n\\n6. **Human-AI Collaboration**: Exploring how AI can augment human intelligence, enhance productivity, and create effective collaborative systems in various fields.\\n\\n7. **Foundation Models and AI Democratization**: The development of large foundation models and the push to make AI technologies more accessible to a wider audience are major trends.\\n\\nThese topics are constantly evolving, and new issues may arise as the field progresses.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 310, 'prompt_tokens': 28, 'total_tokens': 338, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-c992d34b-53f3-4d9b-9263-74268f97623e-0', usage_metadata={'input_tokens': 28, 'output_tokens': 310, 'total_tokens': 338, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat model\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "chat_model = ChatOpenAI(api_key=api_key, model='gpt-4o-mini')\n",
    "\n",
    "\n",
    "messages = [SystemMessage(content='You are a Scientist in AI.'),             # instruct a system to behave in certain way: tone, rules, how respond\n",
    "            HumanMessage(content=\"Which is the most hot topic in AI now?\")]  # input or queries made by the user/human    \n",
    "\n",
    "# Test chat model \n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_______________________________________________\\nJob Title: Machine Learning Resident - Client: Jotson (12 months)\\nCompany Name: Alberta Machine Intelligence Institute\\nLocation: Edmonton, AB, Canada\\nDescription: Salary:\\n\\nJoin us for a unique ML Resident role tackling time-series problems in the energy domain with ML/DL. Youll collaborate with a dynamic and fast-paced team of machine learning scientists and domain experts, developing innovative models and products with energy data.\\n\\n- Maithrreye Srinivasan, Machine Learning Scientist and Dave Staszak, Lead Machine Learning Scientist\\n\\nAbout the Role\\n\\nThis is a paid residency that will be undertaken over a twelve-month period with the potential to be hired by our client afterwards (note: at the discretion of the client and with the requirement of being located in Calgary at that time). The resident will be reporting to an Amii Machine Learning Scientist and regularly consult with the Client team to share insights and engage in knowledge transfer activities.\\n\\nAbout our Client\\n\\nJotson's mission is to help Canadians become informed and confident in making energy-related decisions. They achieve this by making household energy data easy to access, track, and understand. The company has decades of experience working in the energy industry and looks to apply its knowledge to bridge the gap between the energy sector and the everyday consumer.\\n\\nAbout the Project\\n\\nJotson aims to develop a machine-learning solution for detecting anomalies in energy consumption patterns for household and business properties. This solution will alert consumers when energy consumption or charges deviate from expected patterns. Anomaly detection plays a crucial role in monitoring and managing energy usage by flagging unusual consumption patterns or outliers. Anomalies may indicate:\\n• Equipment inefficiencies or failures.\\n• Opportunities to detect energy inefficiencies early and take corrective action.\\n• Misaligned energy systems or operational issues.\\n• Opportunities for energy savings or optimization.\\n• Inaccurate metering/billing that can lead to financial losses.\\n\\nRequired Skills / Expertise\\n\\nWere looking for a talented and enthusiastic individual with solid knowledge of machine learning and experience working with time series data.\\n\\nKey Responsibilities:\\n• Clean, preprocess, and curate historical energy usage datasets.\\n• Conduct exploratory data analysis to identify patterns and anomalies.\\n• Design, build, train, and evaluate ML/DL models\\n• Develop data and ML workflows\\n• Undertake applied research on ML techniques to address the limitations in existing models and develop new approaches\\n• Collaborate with project team and stakeholders to develop minimum viable products (MVPs) and client-centric solutions\\n\\nRequired Qualifications:\\n• Completion of a Computing Science or ML graduate program, MSc. or Ph.D\\n• Research or project experience working with time series data and classical time series models (ARIMA, Facebook Prophet, etc.)\\n• Solid understanding and experience in applications of deep learning techniques such as sequence models (RNNs, LSTMs, GRUs, Transformers, etc.) or multi task learning\\n• Proficient in Python programming language and related ML frameworks, libraries and toolkits (e.g. Scikit learn, Keras, Tensorflow, Pandas, Jupyter notebooks)\\n• A positive attitude towards learning and understanding a new applied domain\\n• Must be legally eligible to work in Canada\\n\\nPreferred Qualifications:\\n• Publication record in peer-reviewed academic conferences or relevant journals in machine learning\\n• Familiarity with time series anomaly detection methods\\n• Experience/familiarity with software engineering best practices\\n• Experience using cloud platforms (GCP, AWS, Azure, etc.)\\n\\nNon-Technical Requirements:\\n• Desire to take ownership of a problem and demonstrated leadership skills\\n• Interdisciplinary team player enthusiastic about working together to achieve excellence\\n• Capable of critical and independent thought\\n• Able to communicate technical concepts clearly and advise on the application of machine intelligence\\n• Intellectual curiosity and the desire to learn new things, techniques, and technologies\\n\\nWhy You Should Apply\\n\\nBesides gaining industry experience, additional perks include:\\n• Work under the mentorship of an Amii Lead Scientist for the duration of the project\\n• Participate in professional development activities\\n• Gain access to the Amii community and events\\n• Build your professional network\\n• The opportunity for a permanent machine learning role at the clients organization at the end of the term (at the clients discretion)\\n\\nLocation\\n\\nPreference for Calgary or Edmonton\\n\\nAbout Amii\\n\\nOne of Canadas three main institutes for artificial intelligence (AI) and machine learning, our world-renowned researchers drive fundamental and applied research at the University of Alberta (and other academic institutions), training some of the worlds top scientific talent. Our cross-functional teams work collaboratively with Alberta-based businesses and organizations to build AI capacity and translate scientific advancement into industry adoption and economic impact.\\n\\nHow to Apply\\n\\nIf this sounds like the opportunity you've been waiting for, please dont wait for the closing February 24, 2025 to apply - were excited to add a new member to the Amii team for this role, and the posting may come down sooner than the closing date if we find the right candidate before the posting closes! When sending your application, please send your resume and cover letter indicating why you think you'd be a fit for Amii. In your cover letter, please include one professional accomplishment you are most proud of and why.\\n\\nApplicants must be legally eligible to work in Canada at the time of application.\\n\\nAmii is an equal opportunity employer and values a diverse workforce. We encourage applications from all qualified individuals without regard to ethnicity, religion, gender identity, sexual orientation, age or disability. Accommodations for disability-related needs throughout the recruitment and selection process are available upon request. Any information provided by you for accommodations will be kept confidential and wont be used in the selection process.\\n_______________________________________________\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tools are classes that an Agent uses to interact with the world. https://python.langchain.com/api_reference/community/tools.html \n",
    "\n",
    "from langchain_community.tools.google_jobs import GoogleJobsQueryRun\n",
    "from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper\n",
    "\n",
    "api_key_serpapi = os.getenv('SERPAPI_API_KEY')\n",
    "os.environ[\"SERPAPI_API_KEY\"] = api_key_serpapi\n",
    "\n",
    "# Take special care of description\n",
    "description_googlejobs = \"\"\"\n",
    "A wrapper around Google Jobs Search. \n",
    "Useful for when you need to get information aboutgoogle search Jobs from Google JobsInput should be a search query. \n",
    "\"\"\"\n",
    "\n",
    "googlejobs = GoogleJobsQueryRun(api_wrapper=GoogleJobsAPIWrapper(), \n",
    "                                     description=description_googlejobs)\n",
    "\n",
    "# Example usage or run(): \n",
    "googlejobs.run(\"Can I get a list of 3 job posting related to machine learning in alberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [googlejobs,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This agent from LangChain is not good - langchain.agents.react.agent.create_react_agent\n",
    "- Better use from the LangGraph (offers a more flexible and full-featured)\n",
    "\n",
    "There are agent types in LangChain:\n",
    "\n",
    "- React agents: Use reasoning and actions to decide on the best steps \n",
    "- Multi-agent: Divide complicated problems into units of work that can be targeted by specialized agents \n",
    "- Conversational agents: Engage in dialogue and maintain context across multiple interactions \n",
    "- Structured chat agents: Parse inputs and outputs into structured formats \n",
    "- Tool calling agents: Use tools in a straightforward way \n",
    "- Self-ask with search: Split queries into smaller steps to handle them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    " \n",
    "prompt_system = SystemMessage(\"You are a recruiter, who is trying to help me in finding suitable jobs\")\n",
    "prompt_human  = HumanMessage(\"Find me the most recent Machine Learning job in Alberta, specify when the job was posted\")\n",
    "\n",
    "agent = create_react_agent(chat_model,\n",
    "                           tools,\n",
    "                           state_modifier=prompt_system)\n",
    "\n",
    "response = agent.invoke({\"messages\": prompt_human})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent Machine Learning job in Alberta is for the position of **Machine Learning Engineer** at **Ontopical** in Calgary, AB, Canada. \n",
      "\n",
      "### Job Details:\n",
      "- **Posted Date:** Not specified in the job details provided\n",
      "- **Location:** Calgary, AB or Vancouver, BC\n",
      "- **Description:** The role involves developing, deploying, and maintaining production-ready scalable ML models, along with other responsibilities related to NLP research and business insights.\n",
      "\n",
      "If you would like to know more about the application process or require additional information, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][3].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
