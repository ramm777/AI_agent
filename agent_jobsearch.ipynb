{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libraries:\n",
    "\n",
    "1) Install miniconda from the website\n",
    "2) Add conda to PATH:\n",
    "     - Start Menu and search for \"Environment Variables.\"\n",
    "     - Click on \"Edit the system environment variables.\"\n",
    "     - In the System Properties window, click on \"Environment Variables.\"\n",
    "     - In the Environment Variables window, find and select the Path.\n",
    "     - Add new: C:\\ProgramData\\miniconda3\\Scripts (or where yours is located).\n",
    "\n",
    "3) Install libs:\n",
    "\n",
    "Create a new virtual environment named 'langchain' with Python 3.12\n",
    "```\n",
    "conda create -n langchain python=3.12 -y\n",
    "```\n",
    "List all environments (the active one will be marked with an asterisk)\n",
    "```\n",
    "conda env list\n",
    "```\n",
    "In PowerShell (admin): Set the execution policy to RemoteSigned for the current user\n",
    "```\n",
    "Set-ExecutionPolicy RemoteSigned -Scope CurrentUser\n",
    "```\n",
    "\n",
    "```\n",
    "conda activate langchain\n",
    "pip install langchain langchain_openai langchain_community langgraph ipykernel python-dotenv\n",
    "```\n",
    "\n",
    "If you encounter a dependency resolver error with pip:\n",
    "```\n",
    "pip install google-auth # Must be <3.0.dev0,>=2.14.1\n",
    "```\n",
    "\n",
    "```\n",
    "ipython kernel install --user --name=langchain\n",
    "pip install google-search-results\n",
    "pip install matplotlib\n",
    "pip install wikipedia\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.agent_toolkits.load_tools import get_all_tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  52\n",
      "sleep wolfram-alpha google-search google-search-results-json searx-search-results-json bing-search metaphor-search ddg-search google-books google-lens\n",
      "google-serper google-scholar google-finance google-trends google-jobs google-serper-results-json searchapi searchapi-results-json serpapi dalle-image-generator\n",
      "twilio searx-search merriam-webster wikipedia arxiv golden-query pubmed human awslambda stackexchange\n",
      "sceneXplain graphql openweathermap-api dataforseo-api-search dataforseo-api-search-json eleven_labs_text2speech google_cloud_texttospeech read_file reddit_search news-api\n",
      "tmdb-api podcast-api memorize llm-math open-meteo-api requests requests_get requests_post requests_patch requests_put\n",
      "requests_delete terminal\n"
     ]
    }
   ],
   "source": [
    "# load_tools() is only a shorthand function. It's better to properly use langchain_community.tools\n",
    "all_tool_names = get_all_tool_names()\n",
    "print('length: ', len(all_tool_names))\n",
    "\n",
    "for i in range(0, len(all_tool_names), 10):\n",
    "    print(\" \".join(all_tool_names[i:i+10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of LLMs:\n",
    "- Language models - input stings and generate strings. They are typically older and work best to answer individual user queries.\n",
    "- Chat model - inputs a sequence of messages, and generates responses that are contextually aware of the conversation flow. By default does not remember past conversations (stateless), but sometimes conversational memory is implemented. \n",
    "- Instruct models - optimized to follow specific instructions and perform tasks rather than engage in open-ended dialogue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, three of the hottest topics in the field of artificial intelligence include:\n",
      "\n",
      "1. **Generative AI**: This area focuses on models that can generate new content, such as text, images, music, and videos. The rapid development and application of models like OpenAI's GPT-4 and DALL-E have received significant attention, leading to discussions about their ethical implications, use cases, and potential for creative industries.\n",
      "\n",
      "2. **AI Ethics and Regulation**: The growing capabilities of AI have sparked crucial conversations around ethics, bias, transparency, and accountability. Governments and organizations are exploring frameworks for AI governance to ensure responsible deployment and to mitigate risks associated with AI technologies. This includes discussions on data privacy, algorithmic bias, and the societal impact of AI.\n",
      "\n",
      "3. **AI in Healthcare**: The use of AI in healthcare continues to expand, particularly in areas such as diagnostics, personalized medicine, drug discovery, and patient care optimization. Advances in machine learning and computer vision have shown significant promise for improving outcomes, but they also raise questions regarding data security, patient privacy, and the integration of AI in clinical settings.\n",
      "\n",
      "These topics underscore the intersection of technological advancements with social, ethical, and practical considerations in the evolving AI landscape.\n"
     ]
    }
   ],
   "source": [
    "# Chat model\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "chat_model = ChatOpenAI(api_key=api_key, model='gpt-4o-mini')\n",
    "\n",
    "\n",
    "messages = [SystemMessage(content='You are a Scientist in AI.'),                # instruct a system to behave in certain way: tone, rules, how respond\n",
    "            HumanMessage(content=\"Which are the most 3 hot topic in AI now?\")]  # input or queries made by the user/human    \n",
    "\n",
    "print(chat_model.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools are classes that an Agent uses to interact with the world. https://python.langchain.com/api_reference/community/tools.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________________________\n",
      "Job Title: Machine Learning Resident - Client: Jotson (12 months)\n",
      "Company Name: Alberta Machine Intelligence Institute\n",
      "Location: Edmonton, AB, Canada\n",
      "Description: Salary:\n",
      "\n",
      "Join us for a unique ML Resident role tackling time-series problems in the energy domain with ML/DL. Youll collaborate with a dynamic and fast-paced team of machine learning scientists and domain experts, developing innovative models and products with energy data.\n",
      "\n",
      "- Maithrreye Srinivasan, Machine Learning Scientist and Dave Staszak, Lead Machine Learning Scientist\n",
      "\n",
      "About the Role\n",
      "\n",
      "This is a paid residency that will be undertaken over a twelve-month period with the potential to be hired by our client afterwards (note: at the discretion of the client and with the requirement of being located in Calgary at that time). The resident will be reporting to an Amii Machine Learning Scientist and regularly consult with the Client team to share insights and engage in knowledge t\n"
     ]
    }
   ],
   "source": [
    "# Google jobs tool\n",
    "\n",
    "from langchain_community.tools.google_jobs import GoogleJobsQueryRun\n",
    "from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper\n",
    "\n",
    "api_key_serpapi = os.getenv('SERPAPI_API_KEY')\n",
    "os.environ[\"SERPAPI_API_KEY\"] = api_key_serpapi\n",
    "\n",
    "# Take special care of description\n",
    "description_googlejobs = \"\"\"\n",
    "A wrapper around Google Jobs Search. \n",
    "Useful for when you need to get information aboutgoogle search Jobs from Google JobsInput should be a search query. \n",
    "\"\"\"\n",
    "\n",
    "googlejobs = GoogleJobsQueryRun(api_wrapper=GoogleJobsAPIWrapper(), \n",
    "                                     description=description_googlejobs)\n",
    "\n",
    "# Example usage or run(): \n",
    "response_g = googlejobs.run(\"Can I get a list of 3 job posting related to machine learning in alberta\")\n",
    "print(response_g[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golden query tool. 10 free queries\n",
    "if False: \n",
    "    import json\n",
    "    from langchain_community.utilities.golden_query import GoldenQueryAPIWrapper\n",
    "\n",
    "    api_key_golden = os.getenv('GOLDEN_API_KEY')\n",
    "    golden_query = GoldenQueryAPIWrapper()\n",
    "\n",
    "    json.loads(golden_query.run(\"companies in nanotech\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun  \n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "description_wiki = \"\"\"\n",
    "A tool to explain things in text format. Use this tool if you think the user  asked concept is best explained through text.\n",
    "\"\"\" \n",
    "\n",
    "wiki_api_wrapper = WikipediaAPIWrapper(doc_content_chars_max=280)\n",
    "wikipedia = WikipediaQueryRun(description=description_wiki,\n",
    "                               api_wrapper=wiki_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [googlejobs, wikipedia]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This agent (langchain.agents.react.agent.create_react_agent) from LangChain - is not good \n",
    "- Better use from the LangGraph (offers a more flexible and full-featured)\n",
    "\n",
    "There are agent types in LangChain:\n",
    "\n",
    "- React agents: Use reasoning and actions to decide on the best steps \n",
    "- Multi-agent: Divide complicated problems into units of work that can be targeted by specialized agents \n",
    "- Conversational agents: Engage in dialogue and maintain context across multiple interactions \n",
    "- Structured chat agents: Parse inputs and outputs into structured formats \n",
    "- Tool calling agents: Use tools in a straightforward way \n",
    "- Self-ask with search: Split queries into smaller steps to handle them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    " \n",
    "prompt_system = SystemMessage(\"You are a recruiter, who is trying to help me in finding suitable jobs\")\n",
    "prompt_human  = HumanMessage(\"Find me the most recent Machine Learning job in Alberta, specify when the job was posted\")\n",
    "\n",
    "agent = create_react_agent(chat_model,\n",
    "                           tools,\n",
    "                           state_modifier=prompt_system)\n",
    "\n",
    "response = agent.invoke({\"messages\": prompt_human})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent Machine Learning job posted in Alberta is for a **Machine Learning Engineer** at **Ontopical** in Calgary, AB. \n",
      "\n",
      "### Job Details:\n",
      "- **Company:** Ontopical\n",
      "- **Location:** Calgary, Alberta, Canada\n",
      "- **Job Description:** The position involves developing, deploying, and maintaining production-ready scalable ML models, among other responsibilities.\n",
      "- **Qualifications:** M.Sc. in related fields, experience with machine learning packages, cloud platforms, and good organizational skills.\n",
      "\n",
      "The specific posting date is not mentioned in the provided information, but it is identified as the most recent job in the category. If you want more information or how to apply, please let me know!\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][3].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Find me the most recent Machine Learning job in Alberta, specify when the job was posted', additional_kwargs={}, response_metadata={}, id='2bdca494-5473-41d2-8b4f-c0f215dc99a3'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_dCpgU0EhVf9X7cnr5H4jrqIx', 'function': {'arguments': '{\"query\":\"Machine Learning jobs in Alberta\"}', 'name': 'google_jobs'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 146, 'total_tokens': 165, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6cad9110-36a5-43a9-870a-6053bc805133-0', tool_calls=[{'name': 'google_jobs', 'args': {'query': 'Machine Learning jobs in Alberta'}, 'id': 'call_dCpgU0EhVf9X7cnr5H4jrqIx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 146, 'output_tokens': 19, 'total_tokens': 165, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='\\n_______________________________________________\\nJob Title: Machine Learning Engineer\\nCompany Name: Ontopical\\nLocation: Calgary, AB, Canada\\nDescription: Machine Learning Engineer\\n\\nCalgary, Alberta or Vancouver, BC\\n\\nAbout Ontopical\\n\\nOntopical is transforming the way companies discover and win government procurement opportunities. Our cutting-edge market intelligence platform, enhanced by our generative AI Copilot, Oliver, empowers enterprise customers—primarily in construction, engineering, consulting, and software—to detect opportunities early through comprehensive data insights. As part of our nimble, scale-up culture, you’ll step into an environment where innovation and collaboration drive everything we do.\\n\\nWho We’re Looking For\\n\\nWe are seeking a Machine Learning Engineer with experience working with large unstructured textual datasets. This position will research, implement, and maintain solutions for information extraction, text classification and recommendation.\\n\\nWhat You’ll Work On\\n• Develop, deploy, and maintain production-ready scalable ML models\\n• Develop and test data processing pipelines\\n• Stay up-to-date with the state of the art in NLP research\\n• Explore and gain insights that drive business decision making through exploratory data analysis\\n• Communicate research and development goals and results to both technical and non-technical stakeholders\\n• Evaluate emerging technologies to enhance the overall capabilities of our existing ML systems\\n\\nAbout You\\n• M.Sc. in computer science, statistics, applied mathematics, data science, or related fields\\n• Write production-quality code to deploy ML models as online services and APIs\\n• Excellent knowledge and experience with various machine learning packages and models (e.g., PyTorch, Scikit-Learn)\\n• Experience with ML lifecycle tools (e.g. MLflow, dvc, weights & biases)\\n• Experience developing workflows and models on cloud platforms (e.g., AWS, GCP)\\n• Ability to comfortably switch between independent and collaborative work\\n• Excellent organizational skills and able to balance multiple projects\\n• In-depth knowledge and experience with LLMs\\n• Knowledge of recommender systems and data mining is a plus\\n\\nWhat We Offer\\n• Competitive Compensation & Benefits: Includes dental, health & vision care.\\n• Impactful Work: Shape a platform that’s disrupting government procurement, driving real-world impact for our enterprise customers.\\n• Growth & Development: Collaborate with a talented team and gain exposure to\\n\\nadvanced AI, data scraping, and analytics projects.\\n• Flexible Work: On-site in Calgary with one day remote option, Monday to Friday\\n\\nJob Type\\n• Must be authorized to work in Canada\\n• Strongly preferred that you are based in Calgary, AB or Vancouver, BC.\\n• M.Sc. in computer science, statistics, applied mathematics, data science, or related fields\\n\\nHow to Apply\\n\\nIf you’re excited about this role and meet the requirements, we’d love to hear from you.\\n\\nPlease submit your resume and a brief introduction of your relevant experience. Join us to drive machine learning excellence and accelerate the future of AI-driven\\n\\nmarket intelligence!\\n_______________________________________________\\n\\n', name='google_jobs', id='360dc28a-eebc-45a4-a9cb-1f1d9a752f4a', tool_call_id='call_dCpgU0EhVf9X7cnr5H4jrqIx'),\n",
       " AIMessage(content='The most recent Machine Learning job posted in Alberta is for a **Machine Learning Engineer** at **Ontopical** in Calgary, AB. \\n\\n### Job Details:\\n- **Company:** Ontopical\\n- **Location:** Calgary, Alberta, Canada\\n- **Job Description:** The position involves developing, deploying, and maintaining production-ready scalable ML models, among other responsibilities.\\n- **Qualifications:** M.Sc. in related fields, experience with machine learning packages, cloud platforms, and good organizational skills.\\n\\nThe specific posting date is not mentioned in the provided information, but it is identified as the most recent job in the category. If you want more information or how to apply, please let me know!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 142, 'prompt_tokens': 771, 'total_tokens': 913, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-a99d9069-d5a9-4883-b379-7893e1778249-0', usage_metadata={'input_tokens': 771, 'output_tokens': 142, 'total_tokens': 913, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google_jobs'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages'][1].tool_calls[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Alberta Machine Intelligence Institute (Amii) is a research institute based in Edmonton, Alberta. Established in 2002, its primary focus is on driving innovation in the field of artificial intelligence (AI) and machine learning. Amii collaborates with companies to facilitate the adoption and growth of AI technologies.\n"
     ]
    }
   ],
   "source": [
    "prompt_system = SystemMessage(\"You are my assistant\")\n",
    "prompt_human  = HumanMessage(\"What is Amii (research institute)?\")\n",
    "\n",
    "agent = create_react_agent(chat_model,\n",
    "                           tools,\n",
    "                           state_modifier=prompt_system)\n",
    "\n",
    "response1 = agent.invoke({\"messages\": prompt_human})\n",
    "print(response1['messages'][3].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now see that it is correctly using wikipedia tool to answer my question\n",
    "\n",
    "response1['messages'][1].tool_calls[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Amii (research institute)?', additional_kwargs={}, response_metadata={}, id='03937828-ad79-480c-bf3d-f480aeac6adc'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QdZ9ljswbOEVPP9Ja8LbsMRW', 'function': {'arguments': '{\"query\":\"Amii (research institute)\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 126, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1e06b06d-c8b1-44b0-8d5f-d429e3553698-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Amii (research institute)'}, 'id': 'call_QdZ9ljswbOEVPP9Ja8LbsMRW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 126, 'output_tokens': 19, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Page: Amii (research institute)\\nSummary: Alberta Machine Intelligence Institute (Amii) is a machine learning institute in Edmonton, Alberta. Amii was established in 2002 to drive innovation in the artificial intelligence space and partner with companies to adopt and grow the tech', name='wikipedia', id='1324d78f-8f3f-434c-8b84-dc001b508ed7', tool_call_id='call_QdZ9ljswbOEVPP9Ja8LbsMRW'),\n",
       "  AIMessage(content='The Alberta Machine Intelligence Institute (Amii) is a research institute based in Edmonton, Alberta. Established in 2002, its primary focus is on driving innovation in the field of artificial intelligence (AI) and machine learning. Amii collaborates with companies to facilitate the adoption and growth of AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 206, 'total_tokens': 269, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-a190ed03-fd96-4fb1-a5b9-69bad53e8e4b-0', usage_metadata={'input_tokens': 206, 'output_tokens': 63, 'total_tokens': 269, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
